{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VJhmu7ayq2-W"
   },
   "source": [
    "## 1 - Data loading and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GQL1lih9CouO",
    "outputId": "039b79a6-7b6b-4e2f-9901-8a860717d206"
   },
   "outputs": [],
   "source": [
    "# Install libraries\n",
    "!pip install torch_geometric\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datasets import load_dataset\n",
    "import json\n",
    "import ast\n",
    "import networkx as nx\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import cv2\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv, SAGEConv, HeteroConv\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import NMF, TruncatedSVD\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import umap\n",
    "\n",
    "# Set style for visualizations\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Optional advanced imports (with error handling)\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    XGB_AVAILABLE = True\n",
    "except ImportError:\n",
    "    XGB_AVAILABLE = False\n",
    "    print(\"XGBoost not available. Install with: pip install xgboost\")\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "729dded1f5414924ae378b53875cf9fb",
      "177d3a0d672e49f0ab1a544d1543b880",
      "6211e4a268c044409dbf5a511921b849",
      "94deabc2b8bc42f2b482a983aed0b6db",
      "3d7f9f9ab903465e91e6762234f78d20",
      "1fa710b3408a45c4856a0294133aef69",
      "af77dc19727f49c98b0170c24364ba62",
      "51c54e5110504189bce149351438124b",
      "5917b42ce4cf4907b10c2ecc4479aa07",
      "fa7bbb53d48247c7b796891812024835",
      "a424a83096964f79b30e223c34b1cf91",
      "529ae4a0950f4a04b5faf604c47704b8",
      "d039a0976a544421bcf7166d193611a4",
      "208741a879034a9d8de0c055b14a0da9",
      "461c91b1930b4abb97d3c61186c7c4ae",
      "8717dfc324024341963f9988c7c9d9fe",
      "7eeab89049ae4d2f9ae9d5305f0da15a",
      "e7e3a4412ed2426db9314d84bcedffe9",
      "05b6224556d345ef932a8ad35f38cb31",
      "76f6ae8421f34f96a8a941bf286e000c",
      "633a675a69a0427fa105578b9b02dbc0",
      "c279e35c221740ffb2e2c1bc5144e59c",
      "f903f92a57764bf0a38f0dd92af03f56",
      "681f6b8bdb6c408d9140117ceab7f2c3",
      "45f16f53e40640f8a72d51e2a63f612c",
      "dc5dd3f3df8c4ce29ef041e45f69bf52",
      "8097e060770e48a6ad4ec32baf3c91cb",
      "2e684179c7064d1da129fa0f08f12d53",
      "5b733c932d654d058ca6a17028c9a622",
      "97580ecf30b54bf2bb7ce4ff19dc4079",
      "b2208f7b3ea34aff8f81e29bc1e2d29c",
      "efb19e537b3b49f6b8b778a18393ce97",
      "8520c656f3784efeaffdbdb9dde5d5cf"
     ]
    },
    "id": "v7QXkBJ3CtoA",
    "outputId": "add34852-374e-4358-cb3a-a470204f0178"
   },
   "outputs": [],
   "source": [
    "def load_and_explore_dataset():\n",
    "    \"\"\"Load the MM-Food-100K dataset and perform initial exploration\"\"\"\n",
    "    print(\"Loading dataset from Hugging Face...\")\n",
    "\n",
    "    # Load the dataset\n",
    "    dataset = load_dataset(\"Codatta/MM-Food-100K\")\n",
    "\n",
    "    # Convert to pandas DataFrame for easier manipulation\n",
    "    df = pd.DataFrame(dataset['train'])\n",
    "\n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "    print(\"\\nDataset columns:\")\n",
    "    print(df.columns.tolist())\n",
    "\n",
    "    # Display basic info\n",
    "    print(\"\\nDataset info:\")\n",
    "    print(df.info())\n",
    "\n",
    "    # Display first few rows\n",
    "    print(\"\\nFirst 5 rows:\")\n",
    "    display(df.head())\n",
    "\n",
    "    return df\n",
    "\n",
    "# Load the dataset\n",
    "df_raw = load_and_explore_dataset()\n",
    "\n",
    "def initial_data_analysis(df):\n",
    "    \"\"\"Perform initial data analysis\"\"\"\n",
    "    print(\"=\"*50)\n",
    "    print(\"INITIAL DATA ANALYSIS\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # Check for missing values\n",
    "    print(\"\\nMissing values per column:\")\n",
    "    missing_values = df.isnull().sum()\n",
    "    print(missing_values[missing_values > 0])\n",
    "\n",
    "    # Check food type distribution\n",
    "    print(\"\\nFood type distribution:\")\n",
    "    food_type_counts = df['food_type'].value_counts()\n",
    "    print(food_type_counts)\n",
    "\n",
    "    # Basic nutritional statistics\n",
    "    print(\"\\nNutritional statistics:\")\n",
    "    # Extract nutritional information from JSON\n",
    "    nutrition_cols = ['calories_kcal', 'protein_g', 'fat_g', 'carbohydrate_g']\n",
    "\n",
    "    # Function to extract nutrition values\n",
    "    def extract_nutrition(nutrition_json, key):\n",
    "        try:\n",
    "            if pd.isna(nutrition_json):\n",
    "                return np.nan\n",
    "            nutrition_dict = json.loads(nutrition_json.replace(\"'\", \"\\\"\"))\n",
    "            return nutrition_dict.get(key, np.nan)\n",
    "        except:\n",
    "            return np.nan\n",
    "\n",
    "    for col in nutrition_cols:\n",
    "        df[col] = df['nutritional_profile'].apply(lambda x: extract_nutrition(x, col))\n",
    "\n",
    "    # Display basic stats for nutritional values\n",
    "    print(df[nutrition_cols].describe())\n",
    "\n",
    "    return df\n",
    "\n",
    "# Perform initial analysis\n",
    "df = initial_data_analysis(df_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SEac6bQHv5Dw"
   },
   "source": [
    "### 1B. data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bZvskbMLtOGJ",
    "outputId": "9d9ef04f-e367-4a45-cf5e-8af70c628b2d"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def comprehensive_data_cleaning(df):\n",
    "    \"\"\"\n",
    "    Comprehensive data cleaning and wrangling pipeline for MM-Food-100K dataset\n",
    "    \"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"COMPREHENSIVE DATA CLEANING & WRANGLING\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # Create a copy to avoid modifying the original\n",
    "    df_clean = df.copy()\n",
    "\n",
    "    # Function to extract nutrition values safely\n",
    "    def extract_nutrition(nutrition_json, key):\n",
    "        try:\n",
    "            if pd.isna(nutrition_json):\n",
    "                return np.nan\n",
    "            nutrition_dict = json.loads(nutrition_json.replace(\"'\", \"\\\"\"))\n",
    "            return nutrition_dict.get(key, np.nan)\n",
    "        except:\n",
    "            return np.nan\n",
    "\n",
    "    # Extract nutritional information from JSON first\n",
    "    nutrition_cols = ['calories_kcal', 'protein_g', 'fat_g', 'carbohydrate_g']\n",
    "    for col in nutrition_cols:\n",
    "        df_clean[col] = df_clean['nutritional_profile'].apply(lambda x: extract_nutrition(x, col))\n",
    "\n",
    "\n",
    "    # 1. Handle Missing Values\n",
    "    print(\"1. Handling missing values...\")\n",
    "\n",
    "    # Check missing values\n",
    "    missing_percent = (df_clean.isnull().sum() / len(df_clean)) * 100\n",
    "    print(\"Missing values percentage:\")\n",
    "    print(missing_percent[missing_percent > 0].sort_values(ascending=False))\n",
    "\n",
    "    # Strategy for different columns\n",
    "    missing_strategies = {\n",
    "        # Nutritional data: impute with median by food_type\n",
    "        'calories_kcal': 'median_by_type',\n",
    "        'protein_g': 'median_by_type',\n",
    "        'fat_g': 'median_by_type',\n",
    "        'carbohydrate_g': 'median_by_type',\n",
    "\n",
    "        # Text data: fill with appropriate defaults\n",
    "        'ingredients': 'empty_list', # This column will be replaced by 'ingredients_cleaned'\n",
    "        'cooking_methods': 'unknown', # This column will be replaced by 'cooking_methods_cleaned'\n",
    "        'portion_sizes': 'empty_list', # This column will be replaced by 'portion_weights' and 'total_weight_g'\n",
    "\n",
    "        # Other columns\n",
    "        'dish_name': 'unknown_dish',\n",
    "        'food_type': 'unknown_type'\n",
    "    }\n",
    "\n",
    "    # Apply missing value strategies\n",
    "    for col, strategy in missing_strategies.items():\n",
    "        if col in df_clean.columns and df_clean[col].isnull().sum() > 0:\n",
    "            if strategy == 'median_by_type':\n",
    "                # Impute with median of the same food_type\n",
    "                df_clean[col] = df_clean.groupby('food_type')[col].transform(\n",
    "                    lambda x: x.fillna(x.median()) if x.notnull().sum() > 0 else x.fillna(0)\n",
    "                )\n",
    "            elif strategy == 'empty_list':\n",
    "                df_clean[col] = df_clean[col].fillna('[]')\n",
    "            elif strategy == 'unknown':\n",
    "                df_clean[col] = df_clean[col].fillna('unknown')\n",
    "            elif strategy == 'unknown_dish':\n",
    "                df_clean[col] = df_clean[col].fillna('unknown_dish')\n",
    "            elif strategy == 'unknown_type':\n",
    "                df_clean[col] = df_clean[col].fillna('unknown_type')\n",
    "\n",
    "    # 2. Data Type Conversion and Validation\n",
    "    print(\"\\n2. Data type conversion and validation...\")\n",
    "\n",
    "    # Convert nutritional columns to numeric, handling errors\n",
    "    nutrition_cols = ['calories_kcal', 'protein_g', 'fat_g', 'carbohydrate_g']\n",
    "    for col in nutrition_cols:\n",
    "        df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce')\n",
    "        # Fill any remaining NaN with median after coercion\n",
    "        df_clean[col] = df_clean[col].fillna(df_clean[col].median())\n",
    "\n",
    "    # 3. Ingredient List Processing\n",
    "    print(\"\\n3. Processing ingredient lists...\")\n",
    "\n",
    "    def clean_ingredient_list(ingredient_str):\n",
    "        \"\"\"Clean and standardize ingredient lists\"\"\"\n",
    "        try:\n",
    "            if pd.isna(ingredient_str) or ingredient_str == '[]' or ingredient_str is None:\n",
    "                return []\n",
    "\n",
    "            # Handle different list formats\n",
    "            if isinstance(ingredient_str, str):\n",
    "                # Clean the string\n",
    "                ingredient_str = ingredient_str.strip()\n",
    "                if ingredient_str.startswith('[') and ingredient_str.endswith(']'):\n",
    "                    ingredients = ast.literal_eval(ingredient_str)\n",
    "                else:\n",
    "                    # Handle malformed lists\n",
    "                    ingredients = [ing.strip() for ing in ingredient_str.split(',')]\n",
    "            elif isinstance(ingredient_str, list):\n",
    "                 ingredients = ingredient_str\n",
    "            else:\n",
    "                 return []\n",
    "\n",
    "\n",
    "            # Clean each ingredient\n",
    "            cleaned_ingredients = []\n",
    "            for ingredient in ingredients:\n",
    "                if isinstance(ingredient, str):\n",
    "                    # Standardize formatting\n",
    "                    ing = ingredient.lower().strip()\n",
    "                    # Remove common prefixes/suffixes\n",
    "                    ing = re.sub(r'^\\d+\\s*', '', ing)  # Remove quantities like \"2 \"\n",
    "                    ing = re.sub(r'\\s*\\(.*\\)', '', ing)  # Remove parentheses content\n",
    "                    ing = re.sub(r'\\s*(tbsp|tsp|cup|cups|oz|lb|lbs|g|kg|ml|l)$', '', ing)  # Remove units\n",
    "                    ing = ing.strip()\n",
    "\n",
    "                    if ing and len(ing) > 1:  # Filter out empty/single character ingredients\n",
    "                        cleaned_ingredients.append(ing)\n",
    "\n",
    "            return list(set(cleaned_ingredients))  # Remove duplicates\n",
    "\n",
    "        except (ValueError, SyntaxError, TypeError) as e:\n",
    "            print(f\"Error processing ingredients: {e}\")\n",
    "            return []\n",
    "\n",
    "    df_clean['ingredients_cleaned'] = df_clean['ingredients'].apply(clean_ingredient_list)\n",
    "\n",
    "    # 4. Cooking Methods Processing\n",
    "    print(\"\\n4. Processing cooking methods...\")\n",
    "\n",
    "    def clean_cooking_methods(method_str):\n",
    "        \"\"\"Clean and standardize cooking methods\"\"\"\n",
    "        try:\n",
    "            if pd.isna(method_str) or method_str is None or method_str == 'unknown':\n",
    "                return []\n",
    "\n",
    "            if isinstance(method_str, str):\n",
    "                methods = [m.strip().lower() for m in method_str.split(',')]\n",
    "                methods = [m for m in methods if m and m != 'unknown']\n",
    "                return list(set(methods))  # Remove duplicates\n",
    "            elif isinstance(method_str, list):\n",
    "                 methods = method_str\n",
    "                 methods = [m.strip().lower() for m in methods if isinstance(m, str)]\n",
    "                 methods = [m for m in methods if m and m != 'unknown']\n",
    "                 return list(set(methods))\n",
    "            else:\n",
    "                return []\n",
    "\n",
    "        except (AttributeError, TypeError) as e:\n",
    "            print(f\"Error processing cooking methods: {e}\")\n",
    "            return []\n",
    "\n",
    "    df_clean['cooking_methods_cleaned'] = df_clean['cooking_method'].apply(clean_cooking_methods)\n",
    "\n",
    "    # 5. Portion Size Processing\n",
    "    print(\"\\n5. Processing portion sizes...\")\n",
    "\n",
    "    def extract_portion_weights(portion_str):\n",
    "        \"\"\"Extract weights from portion size information\"\"\"\n",
    "        try:\n",
    "            if pd.isna(portion_str) or portion_str is None or portion_str == '[]':\n",
    "                return [], 0\n",
    "\n",
    "            if isinstance(portion_str, str):\n",
    "                if portion_str.startswith('[') and portion_str.endswith(']'):\n",
    "                    portions = ast.literal_eval(portion_str)\n",
    "                else:\n",
    "                    portions = [p.strip() for p in portion_str.split(',')]\n",
    "            elif isinstance(portion_str, list):\n",
    "                 portions = portion_str\n",
    "            else:\n",
    "                 return [], 0\n",
    "\n",
    "\n",
    "            weights = []\n",
    "            total_weight = 0\n",
    "\n",
    "            for portion in portions:\n",
    "                if isinstance(portion, str) and ':' in portion:\n",
    "                    try:\n",
    "                        # Extract weight value\n",
    "                        weight_part = portion.split(':')[1].strip()\n",
    "                        # Remove units and convert to float\n",
    "                        weight_value = re.sub(r'[^\\d.]', '', weight_part)\n",
    "                        if weight_value:\n",
    "                            weight_float = float(weight_value)\n",
    "                            weights.append(weight_float)\n",
    "                            total_weight += weight_float\n",
    "                    except (ValueError, IndexError):\n",
    "                        continue\n",
    "\n",
    "            return weights, total_weight\n",
    "\n",
    "        except (ValueError, SyntaxError, TypeError) as e:\n",
    "            print(f\"Error processing portion sizes: {e}\")\n",
    "            return [], 0\n",
    "\n",
    "    portion_results = df_clean['portion_size'].apply(extract_portion_weights)\n",
    "    df_clean['portion_weights'] = portion_results.apply(lambda x: x[0])\n",
    "    df_clean['total_weight_g'] = portion_results.apply(lambda x: x[1])\n",
    "\n",
    "    # 6. Outlier Detection and Handling\n",
    "    print(\"\\n6. Handling outliers...\")\n",
    "\n",
    "    def detect_outliers_iqr(series, threshold=1.5):\n",
    "        \"\"\"Detect outliers using IQR method\"\"\"\n",
    "        Q1 = series.quantile(0.25)\n",
    "        Q3 = series.quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - threshold * IQR\n",
    "        upper_bound = Q3 + threshold * IQR\n",
    "        return (series < lower_bound) | (series > upper_bound)\n",
    "\n",
    "    # Detect outliers in nutritional values\n",
    "    outlier_cols = ['calories_kcal', 'protein_g', 'fat_g', 'carbohydrate_g', 'total_weight_g']\n",
    "    for col in outlier_cols:\n",
    "        if col in df_clean.columns:\n",
    "            outliers = detect_outliers_iqr(df_clean[col].dropna())\n",
    "            print(f\"Outliers in {col}: {outliers.sum()} ({outliers.mean()*100:.2f}%)\")\n",
    "\n",
    "            # Cap outliers (winsorization)\n",
    "            if outliers.sum() > 0:\n",
    "                # Using 1st and 99th percentiles as capping values\n",
    "                lower_bound = df_clean[col].quantile(0.01)\n",
    "                upper_bound = df_clean[col].quantile(0.99)\n",
    "                df_clean[col] = df_clean[col].clip(lower_bound, upper_bound)\n",
    "\n",
    "    # 7. Text Data Cleaning\n",
    "    print(\"\\n7. Cleaning text data...\")\n",
    "\n",
    "    def clean_dish_name(name):\n",
    "        \"\"\"Clean and standardize dish names\"\"\"\n",
    "        if pd.isna(name) or name is None or name == 'unknown_dish':\n",
    "            return 'unknown_dish'\n",
    "\n",
    "        name = str(name).strip().lower()\n",
    "        # Remove extra spaces and special characters\n",
    "        name = re.sub(r'[^\\w\\s]', ' ', name)\n",
    "        name = re.sub(r'\\s+', ' ', name)\n",
    "        return name.strip()\n",
    "\n",
    "    df_clean['dish_name'] = df_clean['dish_name'].apply(clean_dish_name)\n",
    "\n",
    "    # 8. Food Type Standardization\n",
    "    print(\"\\n8. Standardizing food types...\")\n",
    "\n",
    "    def standardize_food_type(food_type):\n",
    "        \"\"\"Standardize food type categories\"\"\"\n",
    "        if pd.isna(food_type) or food_type is None or food_type == 'unknown_type':\n",
    "            return 'unknown'\n",
    "\n",
    "        food_type = str(food_type).lower().strip()\n",
    "\n",
    "        # Standardize categories\n",
    "        type_mapping = {\n",
    "            'homemade': 'homemade',\n",
    "            'home made': 'homemade',\n",
    "            'home-made': 'homemade',\n",
    "            'restaurant': 'restaurant',\n",
    "            'restaurant food': 'restaurant',\n",
    "            'raw': 'raw_vegetables_fruits',\n",
    "            'raw vegetables': 'raw_vegetables_fruits',\n",
    "            'raw fruits': 'raw_vegetables_fruits',\n",
    "            'vegetables': 'raw_vegetables_fruits',\n",
    "            'fruits': 'raw_vegetables_fruits',\n",
    "            'packaged': 'packaged_food',\n",
    "            'packaged food': 'packaged_food',\n",
    "            'processed': 'packaged_food'\n",
    "        }\n",
    "\n",
    "        return type_mapping.get(food_type, food_type)\n",
    "\n",
    "    df_clean['food_type_standardized'] = df_clean['food_type'].apply(standardize_food_type)\n",
    "\n",
    "    # 9. Feature Engineering Preparation\n",
    "    print(\"\\n9. Preparing for feature engineering...\")\n",
    "\n",
    "    # Create flags for data quality\n",
    "    df_clean['has_nutrition_data'] = (\n",
    "        (df_clean['calories_kcal'].notna()) &\n",
    "        (df_clean['protein_g'].notna()) &\n",
    "        (df_clean['fat_g'].notna()) &\n",
    "        (df_clean['carbohydrate_g'].notna())\n",
    "    )\n",
    "\n",
    "    df_clean['has_ingredients'] = df_clean['ingredients_cleaned'].apply(lambda x: len(x) > 0)\n",
    "    df_clean['has_cooking_methods'] = df_clean['cooking_methods_cleaned'].apply(lambda x: len(x) > 0)\n",
    "    df_clean['has_portion_data'] = df_clean['total_weight_g'].notna() & (df_clean['total_weight_g'] > 0)\n",
    "\n",
    "    # Calculate data completeness score\n",
    "    df_clean['data_quality_score'] = (\n",
    "        df_clean['has_nutrition_data'].astype(int) +\n",
    "        df_clean['has_ingredients'].astype(int) +\n",
    "        df_clean['has_cooking_methods'].astype(int) +\n",
    "        df_clean['has_portion_data'].astype(int)\n",
    "    ) / 4\n",
    "\n",
    "    # 10. Final Data Quality Report\n",
    "    print(\"\\n10. Final data quality report:\")\n",
    "\n",
    "    quality_report = {\n",
    "        'total_records': len(df_clean),\n",
    "        'records_with_complete_nutrition': df_clean['has_nutrition_data'].sum(),\n",
    "        'records_with_ingredients': df_clean['has_ingredients'].sum(),\n",
    "        'records_with_cooking_methods': df_clean['has_cooking_methods'].sum(),\n",
    "        'records_with_portion_data': df_clean['has_portion_data'].sum(),\n",
    "        'records_with_high_quality': (df_clean['data_quality_score'] >= 0.75).sum(),\n",
    "        'average_data_quality_score': df_clean['data_quality_score'].mean()\n",
    "    }\n",
    "\n",
    "    for metric, value in quality_report.items():\n",
    "        if 'average' in metric:\n",
    "            print(f\"{metric}: {value:.3f}\")\n",
    "        else:\n",
    "            print(f\"{metric}: {value}\")\n",
    "\n",
    "    # 11. Export cleaned data\n",
    "    print(\"\\n11. Exporting cleaned data...\")\n",
    "\n",
    "    # Select only the cleaned columns for further analysis\n",
    "    clean_columns = [\n",
    "        'dish_name', 'food_type_standardized', 'calories_kcal',\n",
    "        'protein_g', 'fat_g', 'carbohydrate_g', 'ingredients_cleaned',\n",
    "        'cooking_methods_cleaned', 'portion_weights', 'total_weight_g',\n",
    "        'has_nutrition_data', 'has_ingredients', 'has_cooking_methods',\n",
    "        'has_portion_data', 'data_quality_score'\n",
    "    ]\n",
    "\n",
    "    # Keep original columns that are already clean or needed for other steps\n",
    "    original_clean_cols = [col for col in df.columns if col not in [\n",
    "        'dish_name', 'food_type', 'nutritional_profile', 'ingredients',\n",
    "        'cooking_method', 'portion_size' # Corrected 'cooking_methods' and 'portion_sizes'\n",
    "    ]]\n",
    "\n",
    "    # Ensure 'sub_dt', 'image_url', 'camera_or_phone_prob', 'food_prob' are included\n",
    "    essential_original_cols = ['sub_dt', 'image_url', 'camera_or_phone_prob', 'food_prob']\n",
    "    for col in essential_original_cols:\n",
    "      if col not in original_clean_cols:\n",
    "        original_clean_cols.append(col)\n",
    "\n",
    "\n",
    "    final_columns = clean_columns + original_clean_cols\n",
    "    # Filter out columns that don't exist in df_clean\n",
    "    df_final = df_clean[[col for col in final_columns if col in df_clean.columns]]\n",
    "\n",
    "    # Save cleaned dataset\n",
    "    df_final.to_csv('mm_food_100k_cleaned.csv', index=False)\n",
    "    print(\"Cleaned dataset saved to 'mm_food_100k_cleaned.csv'\")\n",
    "\n",
    "    return df_final\n",
    "\n",
    "# Enhanced load function with comprehensive cleaning\n",
    "def load_and_clean_dataset():\n",
    "    \"\"\"\n",
    "    Load dataset and apply comprehensive cleaning\n",
    "    \"\"\"\n",
    "    print(\"Loading and cleaning MM-Food-100K dataset...\")\n",
    "\n",
    "    # Load the dataset\n",
    "    dataset = load_dataset(\"Codatta/MM-Food-100K\")\n",
    "    df = pd.DataFrame(dataset['train'])\n",
    "\n",
    "    print(f\"Original dataset shape: {df.shape}\")\n",
    "\n",
    "    # Apply comprehensive cleaning\n",
    "    df_clean = comprehensive_data_cleaning(df)\n",
    "\n",
    "    print(f\"Cleaned dataset shape: {df_clean.shape}\")\n",
    "    print(\"\\nCleaned dataset info:\")\n",
    "    print(df_clean.info())\n",
    "\n",
    "    return df_clean\n",
    "\n",
    "# Load and clean the dataset\n",
    "df = load_and_clean_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lmDfUUbCq8LX"
   },
   "source": [
    "## 2 - EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XtEXubwi0vJM"
   },
   "source": [
    "### **Objective**\n",
    " This comprehensive EDA provides a solid foundation for understanding the cleaned dataset's characteristics, relationships, and patterns, which is essential for effective feature engineering and model building.\n",
    "\n",
    "**The analysis reveals:**\n",
    "\n",
    "    \n",
    "\n",
    "*    Clear relationships between ingredients, cooking methods, and nutritional\n",
    "*   Patterns in food preparation complexity\n",
    "* Insights into dietary characteristics across different food types\n",
    "*Data quality assessment for reliable modeling\n",
    "\n",
    "### **Key Data EDA Steps:**\n",
    "\n",
    "**1. Data Quality**\n",
    "\n",
    "   *  Missing values properly handled\n",
    "\n",
    "   *  Consistent data types and formats\n",
    "\n",
    "*   Outliers identified and treated\n",
    "\n",
    "**2. Nutritional Patterns**\n",
    "\n",
    "   *  Macronutrient distributions and correlations\n",
    "\n",
    "* Energy density analysis\n",
    "\n",
    "*  Portion size characteristics\n",
    "\n",
    "**3. Ingredient Relationships**\n",
    "\n",
    "*     Most common ingredients and their frequencies\n",
    "\n",
    "*     Relationship between ingredient count and nutrition\n",
    "\n",
    "*     Ingredient diversity patterns\n",
    "\n",
    "**4. Cooking Method Impact**\n",
    "\n",
    " *    Most frequently used cooking techniques\n",
    "\n",
    "*  Nutritional differences between cooking methods\n",
    "\n",
    "*     Preparation time analysis\n",
    "\n",
    "**5. Advanced Metrics**\n",
    "\n",
    "*     Macronutrient ratios\n",
    "\n",
    "*     Data quality scores\n",
    "\n",
    "*     Complexity measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "QIkGJH1CDGhW",
    "outputId": "ad832100-6c73-4654-de2b-94393f031a42"
   },
   "outputs": [],
   "source": [
    "def comprehensive_eda_cleaned(df):\n",
    "    \"\"\"\n",
    "    Comprehensive EDA using the cleaned dataset\n",
    "    \"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"COMPREHENSIVE EDA WITH CLEANED DATA\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # 1. Dataset Overview\n",
    "    print(\"1. DATASET OVERVIEW\")\n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "    print(f\"Data types:\\n{df.dtypes.value_counts()}\")\n",
    "\n",
    "    # Check for remaining missing values\n",
    "    missing_values = df.isnull().sum()\n",
    "    missing_percent = (missing_values / len(df)) * 100\n",
    "    print(f\"\\nMissing values:\\n{missing_values[missing_values > 0]}\")\n",
    "    print(f\"Missing percentage:\\n{missing_percent[missing_percent > 0].round(2)}\")\n",
    "\n",
    "    # 2. Basic Statistics\n",
    "    print(\"\\n2. BASIC STATISTICS\")\n",
    "\n",
    "    # Nutritional statistics\n",
    "    nutrition_cols = ['calories_kcal', 'protein_g', 'fat_g', 'carbohydrate_g', 'total_weight_g']\n",
    "    print(\"Nutritional statistics:\")\n",
    "    print(df[nutrition_cols].describe().round(2))\n",
    "\n",
    "    # Ingredient statistics\n",
    "    df['num_ingredients'] = df['ingredients_cleaned'].apply(len)\n",
    "    df['num_cooking_methods'] = df['cooking_methods_cleaned'].apply(len)\n",
    "\n",
    "    print(f\"\\nAverage ingredients per recipe: {df['num_ingredients'].mean():.2f}\")\n",
    "    print(f\"Average cooking methods per recipe: {df['num_cooking_methods'].mean():.2f}\")\n",
    "    # Removed the line referencing 'estimated_prep_time'\n",
    "    # print(f\"Average preparation time: {df['estimated_prep_time'].mean():.2f} minutes\")\n",
    "\n",
    "    # 3. Food Type Analysis\n",
    "    print(\"\\n3. FOOD TYPE ANALYSIS\")\n",
    "\n",
    "    if 'food_type_standardized' in df.columns:\n",
    "        food_type_counts = df['food_type_standardized'].value_counts()\n",
    "        print(\"Food type distribution:\")\n",
    "        for food_type, count in food_type_counts.items():\n",
    "            print(f\"  {food_type}: {count} ({count/len(df)*100:.1f}%)\")\n",
    "\n",
    "        # Nutritional comparison by food type\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        for i, col in enumerate(nutrition_cols[:4]):\n",
    "            row, col_idx = i // 2, i % 2\n",
    "            sns.boxplot(data=df, x='food_type_standardized', y=col, ax=axes[row, col_idx])\n",
    "            axes[row, col_idx].set_title(f'{col} by Food Type')\n",
    "            axes[row, col_idx].tick_params(axis='x', rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # 4. Ingredient Analysis\n",
    "    print(\"\\n4. INGREDIENT ANALYSIS\")\n",
    "\n",
    "    # Get all ingredients\n",
    "    all_ingredients = [ingredient for sublist in df['ingredients_cleaned'] for ingredient in sublist]\n",
    "    ingredient_counts = Counter(all_ingredients)\n",
    "\n",
    "    print(f\"Total unique ingredients: {len(ingredient_counts)}\")\n",
    "    print(f\"Total ingredient instances: {len(all_ingredients)}\")\n",
    "\n",
    "    # Top ingredients\n",
    "    top_ingredients = ingredient_counts.most_common(20)\n",
    "    print(\"\\nTop 20 ingredients:\")\n",
    "    for ingredient, count in top_ingredients:\n",
    "        print(f\"  {ingredient}: {count}\")\n",
    "\n",
    "    # Plot top ingredients\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    ingredients, counts = zip(*top_ingredients)\n",
    "    sns.barplot(x=list(counts), y=list(ingredients))\n",
    "    plt.title('Top 20 Most Common Ingredients')\n",
    "    plt.xlabel('Count')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 5. Cooking Methods Analysis\n",
    "    print(\"\\n5. COOKING METHODS ANALYSIS\")\n",
    "\n",
    "    # Get all cooking methods\n",
    "    all_methods = [method for sublist in df['cooking_methods_cleaned'] for method in sublist]\n",
    "    method_counts = Counter(all_methods)\n",
    "\n",
    "    print(f\"Total unique cooking methods: {len(method_counts)}\")\n",
    "    print(f\"Total method instances: {len(all_methods)}\")\n",
    "\n",
    "    # Top cooking methods\n",
    "    top_methods = method_counts.most_common(15)\n",
    "    print(\"\\nTop 15 cooking methods:\")\n",
    "    for method, count in top_methods:\n",
    "        print(f\"  {method}: {count}\")\n",
    "\n",
    "    # Plot cooking methods\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    methods, counts = zip(*top_methods)\n",
    "    sns.barplot(x=list(counts), y=list(methods))\n",
    "    plt.title('Top 15 Cooking Methods')\n",
    "    plt.xlabel('Count')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 6. Nutritional Analysis\n",
    "    print(\"\\n6. NUTRITIONAL ANALYSIS\")\n",
    "\n",
    "    # Distribution of nutritional values\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "    # Check if 'nutritional_density' exists before adding to list\n",
    "    nutrition_cols_extended = nutrition_cols.copy()\n",
    "    if 'nutritional_density' in df.columns:\n",
    "        nutrition_cols_extended.append('nutritional_density')\n",
    "\n",
    "    for i, col in enumerate(nutrition_cols_extended):\n",
    "        row, col_idx = i // 3, i % 3\n",
    "        if col in df.columns:\n",
    "            sns.histplot(df[col].dropna(), bins=50, ax=axes[row, col_idx], kde=True)\n",
    "            axes[row, col_idx].set_title(f'Distribution of {col}')\n",
    "            axes[row, col_idx].set_xlabel(col)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Correlation matrix\n",
    "    # Ensure all columns exist before calculating correlation\n",
    "    cols_for_corr = [col for col in nutrition_cols_extended if col in df.columns]\n",
    "    if len(cols_for_corr) > 1:\n",
    "        nutritional_corr = df[cols_for_corr].corr()\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(nutritional_corr, annot=True, cmap='coolwarm', center=0, fmt='.2f')\n",
    "        plt.title('Nutritional Values Correlation Matrix')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"\\nInsufficient nutritional columns for correlation matrix.\")\n",
    "\n",
    "\n",
    "    # 7. Portion Size Analysis\n",
    "    print(\"\\n7. PORTION SIZE ANALYSIS\")\n",
    "\n",
    "    if 'total_weight_g' in df.columns:\n",
    "        print(f\"Average portion size: {df['total_weight_g'].mean():.2f}g\")\n",
    "        print(f\"Median portion size: {df['total_weight_g'].median():.2f}g\")\n",
    "        print(f\"Portion size range: {df['total_weight_g'].min():.2f}g - {df['total_weight_g'].max():.2f}g\")\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.histplot(df['total_weight_g'].dropna(), bins=50, kde=True)\n",
    "        plt.title('Distribution of Portion Sizes')\n",
    "        plt.xlabel('Weight (g)')\n",
    "        plt.ylabel('Count')\n",
    "        plt.show()\n",
    "\n",
    "    # 8. Relationship: Ingredients vs Nutrition\n",
    "    print(\"\\n8. INGREDIENTS vs NUTRITION RELATIONSHIP\")\n",
    "\n",
    "    # Scatter plots: Number of ingredients vs nutritional values\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    for i, col in enumerate(nutrition_cols[:4]):\n",
    "        row, col_idx = i // 2, i % 2\n",
    "        sns.scatterplot(data=df, x='num_ingredients', y=col, alpha=0.6, ax=axes[row, col_idx])\n",
    "        axes[row, col_idx].set_title(f'{col} vs Number of Ingredients')\n",
    "        axes[row, col_idx].set_xlabel('Number of Ingredients')\n",
    "        axes[row, col_idx].set_ylabel(col)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Correlation analysis\n",
    "    ingredient_nutrition_corr = df[['num_ingredients'] + nutrition_cols].corr()\n",
    "    print(\"Correlation between ingredient count and nutrition:\")\n",
    "    print(ingredient_nutrition_corr['num_ingredients'][1:].round(3))\n",
    "\n",
    "    # 9. Relationship: Cooking Methods vs Nutrition\n",
    "    print(\"\\n9. COOKING METHODS vs NUTRITION RELATIONSHIP\")\n",
    "\n",
    "    # Analyze nutritional impact of cooking methods\n",
    "    top_methods_list = [method for method, count in top_methods[:8]]\n",
    "    method_nutrition = {}\n",
    "\n",
    "    for method in top_methods_list:\n",
    "        method_recipes = df[df['cooking_methods_cleaned'].apply(lambda x: method in x)]\n",
    "        if len(method_recipes) > 10:\n",
    "            method_nutrition[method] = {\n",
    "                'count': len(method_recipes),\n",
    "                'avg_calories': method_recipes['calories_kcal'].mean(),\n",
    "                'avg_protein': method_recipes['protein_g'].mean(),\n",
    "                'avg_fat': method_recipes['fat_g'].mean(),\n",
    "                'avg_carbs': method_recipes['carbohydrate_g'].mean()\n",
    "            }\n",
    "\n",
    "    # Create comparison plot\n",
    "    methods = list(method_nutrition.keys())\n",
    "    calories = [method_nutrition[m]['avg_calories'] for m in methods]\n",
    "    protein = [method_nutrition[m]['avg_protein'] for m in methods]\n",
    "    fat = [method_nutrition[m]['avg_fat'] for m in methods]\n",
    "    carbs = [method_nutrition[m]['avg_carbs'] for m in methods]\n",
    "\n",
    "    x = np.arange(len(methods))\n",
    "    width = 0.2\n",
    "\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    plt.bar(x - width*1.5, calories, width, label='Calories', alpha=0.8)\n",
    "    plt.bar(x - width/2, protein, width, label='Protein (g)', alpha=0.8)\n",
    "    plt.bar(x + width/2, fat, width, label='Fat (g)', alpha=0.8)\n",
    "    plt.bar(x + width*1.5, carbs, width, label='Carbs (g)', alpha=0.8)\n",
    "\n",
    "    plt.xlabel('Cooking Methods')\n",
    "    plt.ylabel('Nutritional Values')\n",
    "    plt.title('Nutritional Profile by Cooking Method')\n",
    "    plt.xticks(x, methods, rotation=45)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 10. Advanced Nutritional Analysis\n",
    "    print(\"\\n10. ADVANCED NUTRITIONAL ANALYSIS\")\n",
    "\n",
    "    # Macronutrient ratios\n",
    "    # Check if columns exist before calculating ratios\n",
    "    if all(col in df.columns for col in nutrition_cols):\n",
    "        total_macros = df['protein_g'] + df['fat_g'] + df['carbohydrate_g']\n",
    "        df['protein_ratio'] = df['protein_g'] / total_macros.replace(0, 1)\n",
    "        df['fat_ratio'] = df['fat_g'] / total_macros.replace(0, 1)\n",
    "        df['carb_ratio'] = df['carbohydrate_g'] / total_macros.replace(0, 1)\n",
    "\n",
    "        # Plot macronutrient distribution\n",
    "        macro_ratios = ['protein_ratio', 'fat_ratio', 'carb_ratio']\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        for ratio in macro_ratios:\n",
    "            sns.kdeplot(df[ratio].dropna(), label=ratio.replace('_ratio', '').title())\n",
    "        plt.title('Distribution of Macronutrient Ratios')\n",
    "        plt.xlabel('Ratio')\n",
    "        plt.ylabel('Density')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"\\nInsufficient nutritional columns for macronutrient ratio analysis.\")\n",
    "\n",
    "\n",
    "    # Energy density analysis\n",
    "    if 'total_weight_g' in df.columns and 'calories_kcal' in df.columns:\n",
    "        df['energy_density'] = df['calories_kcal'] / df['total_weight_g'].replace(0, 1)\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.histplot(df['energy_density'].dropna(), bins=50, kde=True)\n",
    "        plt.title('Distribution of Energy Density (calories/gram)')\n",
    "        plt.xlabel('Energy Density')\n",
    "        plt.ylabel('Count')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"\\nInsufficient columns for energy density analysis.\")\n",
    "\n",
    "\n",
    "    # 11. Data Quality Assessment\n",
    "    print(\"\\n11. DATA QUALITY ASSESSMENT\")\n",
    "\n",
    "    if 'data_quality_score' in df.columns:\n",
    "        print(f\"Average data quality score: {df['data_quality_score'].mean():.3f}\")\n",
    "        print(f\"Data quality distribution:\")\n",
    "        print(df['data_quality_score'].value_counts().sort_index())\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.histplot(df['data_quality_score'], bins=10, kde=True)\n",
    "        plt.title('Distribution of Data Quality Scores')\n",
    "        plt.xlabel('Data Quality Score')\n",
    "        plt.ylabel('Count')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"\\n'data_quality_score' column not found for quality assessment.\")\n",
    "\n",
    "\n",
    "    # 12. Outlier Analysis\n",
    "    print(\"\\n12. OUTLIER ANALYSIS\")\n",
    "\n",
    "    def detect_outliers(series, threshold=3):\n",
    "        z_scores = np.abs((series - series.mean()) / series.std())\n",
    "        return z_scores > threshold\n",
    "\n",
    "    outlier_cols = ['calories_kcal', 'protein_g', 'fat_g', 'carbohydrate_g', 'total_weight_g']\n",
    "    outlier_results = {}\n",
    "\n",
    "    for col in outlier_cols:\n",
    "        if col in df.columns:\n",
    "            outliers = detect_outliers(df[col].dropna())\n",
    "            outlier_results[col] = {\n",
    "                'count': outliers.sum(),\n",
    "                'percentage': (outliers.sum() / len(df[col].dropna())) * 100\n",
    "            }\n",
    "        else:\n",
    "            outlier_results[col] = {'count': 0, 'percentage': 0.0}\n",
    "\n",
    "\n",
    "    print(\"Outlier analysis:\")\n",
    "    for col, results in outlier_results.items():\n",
    "        print(f\"  {col}: {results['count']} outliers ({results['percentage']:.2f}%)\")\n",
    "\n",
    "    # 13. Temporal Patterns (Preparation Time)\n",
    "    print(\"\\n13. TEMPORAL PATTERNS\")\n",
    "\n",
    "    if 'estimated_prep_time' in df.columns:\n",
    "        print(f\"Preparation time statistics:\")\n",
    "        print(f\"  Mean: {df['estimated_prep_time'].mean():.2f} minutes\")\n",
    "        print(f\"  Median: {df['estimated_prep_time'].median():.2f} minutes\")\n",
    "        print(f\"  Std: {df['estimated_prep_time'].std():.2f} minutes\")\n",
    "\n",
    "        # Preparation time distribution\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        sns.histplot(df['estimated_prep_time'].dropna(), bins=30, kde=True)\n",
    "        plt.title('Distribution of Preparation Time')\n",
    "        plt.xlabel('Minutes')\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        sns.boxplot(y=df['estimated_prep_time'].dropna())\n",
    "        plt.title('Boxplot of Preparation Time')\n",
    "        plt.ylabel('Minutes')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Preparation time vs complexity\n",
    "        if 'num_ingredients' in df.columns and 'num_cooking_methods' in df.columns:\n",
    "            complexity_corr = df[['estimated_prep_time', 'num_ingredients', 'num_cooking_methods']].corr()\n",
    "            print(\"Correlation between preparation time and complexity:\")\n",
    "            print(complexity_corr['estimated_prep_time'][1:].round(3))\n",
    "        else:\n",
    "             print(\"\\nInsufficient columns for preparation time vs complexity analysis.\")\n",
    "    else:\n",
    "        print(\"\\n'estimated_prep_time' column not found for temporal analysis.\")\n",
    "\n",
    "\n",
    "    # 14. Comprehensive Summary\n",
    "    print(\"\\n14. COMPREHENSIVE SUMMARY\")\n",
    "\n",
    "    summary_stats = {\n",
    "        'total_recipes': len(df),\n",
    "        'avg_ingredients': df['num_ingredients'].mean(),\n",
    "        'avg_cooking_methods': df['num_cooking_methods'].mean(),\n",
    "        'avg_calories': df['calories_kcal'].mean(),\n",
    "        'avg_protein': df['protein_g'].mean(),\n",
    "        'avg_fat': df['fat_g'].mean(),\n",
    "        'avg_carbs': df['carbohydrate_g'].mean(),\n",
    "        'avg_prep_time': df['estimated_prep_time'].mean() if 'estimated_prep_time' in df.columns else None,\n",
    "        'data_quality': df['data_quality_score'].mean() if 'data_quality_score' in df.columns else None\n",
    "    }\n",
    "\n",
    "    print(\"Dataset Summary:\")\n",
    "    for key, value in summary_stats.items():\n",
    "        if value is not None:\n",
    "            if isinstance(value, float):\n",
    "                print(f\"  {key.replace('_', ' ').title()}: {value:.2f}\")\n",
    "            else:\n",
    "                print(f\"  {key.replace('_', ' ').title()}: {value}\")\n",
    "\n",
    "    return {\n",
    "        'ingredient_counts': ingredient_counts,\n",
    "        'method_counts': method_counts,\n",
    "        'nutritional_stats': df[nutrition_cols].describe(),\n",
    "        'outlier_analysis': outlier_results,\n",
    "        'summary_stats': summary_stats\n",
    "    }\n",
    "\n",
    "# Run comprehensive EDA on cleaned data\n",
    "eda_results = comprehensive_eda_cleaned(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BEfcL-jyrXTY"
   },
   "source": [
    "## 3 - Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n--99YxL2zND"
   },
   "source": [
    "### 3.1 Multimodal Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mNR4BBy63Xzk"
   },
   "source": [
    "Extracts multimodal features including:\n",
    "\n",
    "*    Nutritional ratios and distributions\n",
    "\n",
    "*    Ingredient co-occurrence networks\n",
    "\n",
    "*    Cultural cuisine clustering\n",
    "\n",
    "*   Portion size analysis\n",
    "\n",
    "*    Image quality assessment (placeholder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ditHrR802rXI",
    "outputId": "5625dcbb-b608-44fc-9485-affd35d6d851"
   },
   "outputs": [],
   "source": [
    "def multimodal_feature_extraction(df):\n",
    "    \"\"\"Extract multimodal features from the dataset\"\"\"\n",
    "    print(\"=\"*50)\n",
    "    print(\"MULTIMODAL FEATURE EXTRACTION\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # 1. Nutritional Analysis Features\n",
    "    print(\"\\n1. Nutritional Analysis Features\")\n",
    "\n",
    "    # Calculate nutritional ratios\n",
    "    df['protein_calorie_ratio'] = df['protein_g'] / df['calories_kcal']\n",
    "    df['fat_calorie_ratio'] = df['fat_g'] / df['calories_kcal']\n",
    "    df['carb_calorie_ratio'] = df['carbohydrate_g'] / df['calories_kcal']\n",
    "\n",
    "    # Replace infinities with NaN\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "    # 2. Ingredient Network Analysis\n",
    "    print(\"\\n2. Ingredient Network Analysis\")\n",
    "\n",
    "    # Create ingredient co-occurrence matrix\n",
    "    all_ingredients = list(set([ingredient for sublist in df['ingredients_cleaned'].tolist() for ingredient in sublist]))\n",
    "    ingredient_index = {ingredient: idx for idx, ingredient in enumerate(all_ingredients)}\n",
    "\n",
    "    # Initialize co-occurrence matrix\n",
    "    co_occurrence = np.zeros((len(all_ingredients), len(all_ingredients)))\n",
    "\n",
    "    # Fill co-occurrence matrix\n",
    "    for ingredients in df['ingredients_cleaned']:\n",
    "        for i in range(len(ingredients)):\n",
    "            for j in range(i+1, len(ingredients)):\n",
    "                idx1 = ingredient_index[ingredients[i]]\n",
    "                idx2 = ingredient_index[ingredients[j]]\n",
    "                co_occurrence[idx1, idx2] += 1\n",
    "                co_occurrence[idx2, idx1] += 1\n",
    "\n",
    "    # Create ingredient graph\n",
    "    G = nx.Graph()\n",
    "\n",
    "    # Add nodes\n",
    "    for ingredient in all_ingredients:\n",
    "        G.add_node(ingredient)\n",
    "\n",
    "    # Add edges (only for top ingredients to reduce complexity)\n",
    "    top_ingredients = [ingredient for ingredient, count in Counter(all_ingredients).most_common(50)]\n",
    "\n",
    "    for i in range(len(top_ingredients)):\n",
    "        for j in range(i+1, len(top_ingredients)):\n",
    "            ing1, ing2 = top_ingredients[i], top_ingredients[j]\n",
    "            idx1, idx2 = ingredient_index[ing1], ingredient_index[ing2]\n",
    "            weight = co_occurrence[idx1, idx2]\n",
    "            if weight > 0:\n",
    "                G.add_edge(ing1, ing2, weight=weight)\n",
    "\n",
    "    # Calculate network metrics\n",
    "    degree_centrality = nx.degree_centrality(G)\n",
    "    betweenness_centrality = nx.betweenness_centrality(G)\n",
    "\n",
    "    print(f\"Ingredient network created with {G.number_of_nodes()} nodes and {G.number_of_edges()} edges\")\n",
    "    print(\"Top ingredients by degree centrality:\")\n",
    "    for ingredient in sorted(degree_centrality, key=degree_centrality.get, reverse=True)[:10]:\n",
    "        print(f\"{ingredient}: {degree_centrality[ingredient]:.4f}\")\n",
    "\n",
    "    # 3. Cultural Cuisine Clustering\n",
    "    print(\"\\n3. Cultural Cuisine Clustering\")\n",
    "\n",
    "    # Create features for clustering (simplified approach)\n",
    "    # In a real scenario, we'd use more sophisticated text embeddings\n",
    "    cuisine_keywords = {\n",
    "        'italian': ['pasta', 'tomato', 'basil', 'olive oil', 'parmesan'],\n",
    "        'mexican': ['tortilla', 'chili', 'avocado', 'lime', 'cilantro'],\n",
    "        'asian': ['soy sauce', 'ginger', 'garlic', 'rice', 'sesame oil'],\n",
    "        'indian': ['curry', 'turmeric', 'cumin', 'coriander', 'garam masala'],\n",
    "        'american': ['cheese', 'beef', 'potato', 'ketchup', 'mayonnaise']\n",
    "    }\n",
    "\n",
    "    def detect_cuisine(ingredients):\n",
    "        scores = {cuisine: 0 for cuisine in cuisine_keywords}\n",
    "        for ingredient in ingredients:\n",
    "            for cuisine, keywords in cuisine_keywords.items():\n",
    "                if ingredient in keywords:\n",
    "                    scores[cuisine] += 1\n",
    "        if max(scores.values()) == 0:\n",
    "            return 'unknown'\n",
    "        return max(scores.items(), key=lambda x: x[1])[0]\n",
    "\n",
    "    df['predicted_cuisine'] = df['ingredients_cleaned'].apply(detect_cuisine)\n",
    "\n",
    "    print(\"Cuisine distribution:\")\n",
    "    print(df['predicted_cuisine'].value_counts())\n",
    "\n",
    "    # 4. Portion Size Analysis\n",
    "    print(\"\\n4. Portion Size Analysis\")\n",
    "\n",
    "    # Calculate realistic serving sizes based on food type\n",
    "    serving_sizes = df.groupby('food_type_standardized')['total_weight_g'].agg(['mean', 'median', 'std']).round(2)\n",
    "    print(\"Serving sizes by food type:\")\n",
    "    print(serving_sizes)\n",
    "\n",
    "    # Flag unrealistic portion sizes (outside 2 standard deviations)\n",
    "    def flag_unrealistic_portion(row):\n",
    "        if pd.isna(row['total_weight_g']):\n",
    "            return False\n",
    "        food_type = row['food_type_standardized']\n",
    "        # Check if food_type exists in serving_sizes index\n",
    "        if food_type not in serving_sizes.index:\n",
    "            return False # Or handle as appropriate\n",
    "\n",
    "        stats = serving_sizes.loc[food_type]\n",
    "        # Handle potential NaN or Inf in stats\n",
    "        if pd.isna(stats['mean']) or pd.isna(stats['std']):\n",
    "            return False\n",
    "\n",
    "        lower_bound = stats['mean'] - 2 * stats['std']\n",
    "        upper_bound = stats['mean'] + 2 * stats['std']\n",
    "        return row['total_weight_g'] < lower_bound or row['total_weight_g'] > upper_bound\n",
    "\n",
    "    df['unrealistic_portion'] = df.apply(flag_unrealistic_portion, axis=1)\n",
    "    print(f\"Number of unrealistic portion sizes: {df['unrealistic_portion'].sum()}\")\n",
    "\n",
    "    # 5. Image Quality Assessment (simulated - would need actual images)\n",
    "    print(\"\\n5. Image Quality Assessment\")\n",
    "\n",
    "    # This would normally require downloading and processing images\n",
    "    # For demonstration, we'll create placeholder features\n",
    "    df['image_quality_score'] = np.random.uniform(0.7, 1.0, len(df))  # Placeholder\n",
    "\n",
    "    print(\"Image quality score distribution:\")\n",
    "    print(df['image_quality_score'].describe())\n",
    "\n",
    "    return df, G\n",
    "\n",
    "# Extract multimodal features\n",
    "df, ingredient_graph = multimodal_feature_extraction(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V43UsMma23iI"
   },
   "source": [
    "### 3.2 Nutritional Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_PLybMDK3WZI"
   },
   "source": [
    "Engineers advanced nutritional features including:\n",
    "\n",
    "*    Macronutrient ratios\n",
    "\n",
    "*     Health indicators (high-fiber, low-sodium, balanced meal flags)\n",
    "\n",
    "*     Dietary compatibility (vegan, keto, paleo, gluten-free)\n",
    "\n",
    "*     Nutritional density scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "PFnwj2fZDtPe",
    "outputId": "109f8a63-d130-46c9-94c5-9e8c5258daaf"
   },
   "outputs": [],
   "source": [
    "def nutritional_engineering(df):\n",
    "    \"\"\"Create advanced nutritional features\"\"\"\n",
    "    print(\"=\"*50)\n",
    "    print(\"NUTRITIONAL ENGINEERING\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # 1. Macronutrient Ratios\n",
    "    print(\"\\n1. Macronutrient Ratios\")\n",
    "\n",
    "    # Calculate macronutrient percentages\n",
    "    total_macros = df['protein_g'] + df['fat_g'] + df['carbohydrate_g']\n",
    "    df['protein_pct'] = df['protein_g'] / total_macros * 100\n",
    "    df['fat_pct'] = df['fat_g'] / total_macros * 100\n",
    "    df['carb_pct'] = df['carbohydrate_g'] / total_macros * 100\n",
    "\n",
    "    # Replace infinities with NaN\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "    # 2. Health Indicators\n",
    "    print(\"\\n2. Health Indicators\")\n",
    "\n",
    "    # High fiber flag (assuming we had fiber data)\n",
    "    # For demonstration, we'll create a placeholder based on ingredients\n",
    "    high_fiber_ingredients = ['whole wheat', 'oats', 'beans', 'lentils', 'broccoli',\n",
    "                             'avocado', 'berries', 'apples', 'nuts', 'seeds']\n",
    "\n",
    "    def has_high_fiber(ingredients):\n",
    "        return any(ingredient in high_fiber_ingredients for ingredient in ingredients)\n",
    "\n",
    "    df['high_fiber'] = df['ingredients_cleaned'].apply(has_high_fiber)\n",
    "\n",
    "    # Low sodium flag (placeholder)\n",
    "    df['low_sodium'] = np.random.choice([True, False], len(df), p=[0.3, 0.7])\n",
    "\n",
    "    # Balanced meal flag (reasonable distribution of macros)\n",
    "    def is_balanced(row):\n",
    "        if pd.isna(row['protein_pct']) or pd.isna(row['fat_pct']) or pd.isna(row['carb_pct']):\n",
    "            return False\n",
    "        return (15 <= row['protein_pct'] <= 35 and\n",
    "                20 <= row['fat_pct'] <= 40 and\n",
    "                35 <= row['carb_pct'] <= 65)\n",
    "\n",
    "    df['balanced_meal'] = df.apply(is_balanced, axis=1)\n",
    "\n",
    "    print(f\"High fiber meals: {df['high_fiber'].sum()}\")\n",
    "    print(f\"Low sodium meals: {df['low_sodium'].sum()}\")\n",
    "    print(f\"Balanced meals: {df['balanced_meal'].sum()}\")\n",
    "\n",
    "    # 3. Dietary Compatibility\n",
    "    print(\"\\n3. Dietary Compatibility\")\n",
    "\n",
    "    # Define dietary restrictions\n",
    "    vegan_restricted = ['meat', 'chicken', 'beef', 'pork', 'fish', 'seafood', 'egg',\n",
    "                       'dairy', 'milk', 'cheese', 'butter', 'honey', 'gelatin']\n",
    "    keto_restricted = ['sugar', 'honey', 'maple syrup', 'rice', 'pasta', 'bread', 'potato',\n",
    "                      'corn', 'beans', 'grains', 'fruit juice']\n",
    "    paleo_restricted = ['dairy', 'legumes', 'grains', 'processed food', 'refined sugar',\n",
    "                       'vegetable oil', 'soy', 'peanut']\n",
    "    gluten_restricted = ['wheat', 'barley', 'rye', 'bread', 'pasta', 'cereal', 'couscous']\n",
    "\n",
    "    def check_diet_compatibility(ingredients, diet_restrictions):\n",
    "        return not any(ingredient in diet_restrictions for ingredient in ingredients)\n",
    "\n",
    "    df['vegan'] = df['ingredients_cleaned'].apply(lambda x: check_diet_compatibility(x, vegan_restricted))\n",
    "    df['keto'] = df['ingredients_cleaned'].apply(lambda x: check_diet_compatibility(x, keto_restricted))\n",
    "    df['paleo'] = df['ingredients_cleaned'].apply(lambda x: check_diet_compatibility(x, paleo_restricted))\n",
    "    df['gluten_free'] = df['ingredients_cleaned'].apply(lambda x: check_diet_compatibility(x, gluten_restricted))\n",
    "\n",
    "    print(\"Dietary compatibility counts:\")\n",
    "    print(f\"Vegan: {df['vegan'].sum()}\")\n",
    "    print(f\"Keto: {df['keto'].sum()}\")\n",
    "    print(f\"Paleo: {df['paleo'].sum()}\")\n",
    "    print(f\"Gluten-free: {df['gluten_free'].sum()}\")\n",
    "\n",
    "    # 4. Nutritional Density Scores\n",
    "    print(\"\\n4. Nutritional Density Scores\")\n",
    "\n",
    "    # Create a simplified nutritional density score\n",
    "    # In a real scenario, this would incorporate more nutrients\n",
    "    def calculate_nutritional_density(row):\n",
    "        if pd.isna(row['calories_kcal']) or row['calories_kcal'] == 0:\n",
    "            return np.nan\n",
    "\n",
    "        # Base score on protein content (higher protein = more nutrient dense)\n",
    "        protein_score = min(row['protein_g'] / row['calories_kcal'] * 100, 10)\n",
    "\n",
    "        # Adjust based on food type\n",
    "        food_type_bonus = {\n",
    "            'raw_vegetables_fruits': 2,\n",
    "            'homemade': 1,\n",
    "            'restaurant': 0,\n",
    "            'packaged_food': -1\n",
    "        }.get(row['food_type_standardized'], 0)\n",
    "\n",
    "        # Adjust based on balanced meal flag\n",
    "        balance_bonus = 2 if row['balanced_meal'] else 0\n",
    "\n",
    "        return protein_score + food_type_bonus + balance_bonus\n",
    "\n",
    "    df['nutritional_density'] = df.apply(calculate_nutritional_density, axis=1)\n",
    "\n",
    "    print(\"Nutritional density score distribution:\")\n",
    "    print(df['nutritional_density'].describe())\n",
    "\n",
    "    # Visualize nutritional density by food type\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(data=df, x='food_type_standardized', y='nutritional_density')\n",
    "    plt.title('Nutritional Density by Food Type')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return df\n",
    "\n",
    "# Perform nutritional engineering\n",
    "df = nutritional_engineering(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oNcjbK2R3v72"
   },
   "source": [
    "## 4 - Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fsZU2Z6Eh1RC"
   },
   "outputs": [],
   "source": [
    "# Add these imports at the top of Section 4 if they're missing:\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m_fYMxsrh4AH"
   },
   "outputs": [],
   "source": [
    "# Add memory check function\n",
    "def check_memory():\n",
    "    \"\"\"Check memory usage and trigger garbage collection if needed\"\"\"\n",
    "    memory = psutil.virtual_memory()\n",
    "    if memory.percent > 80:\n",
    "        print(f\"Warning: Memory usage at {memory.percent}%\")\n",
    "        gc.collect()\n",
    "    return memory.percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Zn1o6iCsXpoU",
    "outputId": "999d9025-ed5f-4a79-e01e-1d0d251f05a8"
   },
   "outputs": [],
   "source": [
    "def memory_efficient_ml_pipeline(df, target_variable='calories_kcal', test_size=0.2, random_state=42, max_samples=100000):\n",
    "    \"\"\"\n",
    "    Memory-efficient ML pipeline that samples data to prevent crashes\n",
    "    \"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"MEMORY-EFFICIENT MACHINE LEARNING PIPELINE\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # Check memory at start\n",
    "    memory_usage = check_memory()\n",
    "    print(f\"Starting memory usage: {memory_usage:.1f}%\")\n",
    "\n",
    "    # 1. Sample data if too large\n",
    "    if len(df) > max_samples:\n",
    "        print(f\"Sampling {max_samples} rows from {len(df)} total rows to prevent memory issues\")\n",
    "        df_sample = df.sample(n=max_samples, random_state=random_state)\n",
    "    else:\n",
    "        df_sample = df.copy()\n",
    "\n",
    "    # 2. Select only essential features to reduce memory usage\n",
    "    essential_features = [\n",
    "        'protein_g', 'fat_g', 'carbohydrate_g', 'total_weight_g',\n",
    "        'num_ingredients', 'num_cooking_methods'\n",
    "    ]\n",
    "\n",
    "    # Add optional features if they exist\n",
    "    optional_features = [\n",
    "        'protein_ratio', 'fat_ratio', 'carb_ratio', 'energy_density',\n",
    "        'nutritional_density', 'cooking_health_score'\n",
    "    ]\n",
    "\n",
    "    # Filter to existing columns\n",
    "    available_features = [col for col in essential_features if col in df_sample.columns]\n",
    "    available_features.extend([col for col in optional_features if col in df_sample.columns])\n",
    "\n",
    "    if len(available_features) < 3:\n",
    "        print(\"ERROR: Insufficient features available for modeling\")\n",
    "        print(f\"Available columns: {list(df_sample.columns)}\")\n",
    "        return None\n",
    "\n",
    "    print(f\"Using features: {available_features}\")\n",
    "\n",
    "    # 3. Handle missing values\n",
    "    X = df_sample[available_features].copy()\n",
    "    y = df_sample[target_variable].copy()\n",
    "\n",
    "    # Check for missing target values\n",
    "    missing_target = y.isna().sum()\n",
    "    if missing_target > 0:\n",
    "        print(f\"Removing {missing_target} rows with missing target values\")\n",
    "        valid_indices = y.notna()\n",
    "        X = X[valid_indices]\n",
    "        y = y[valid_indices]\n",
    "\n",
    "    if len(X) == 0:\n",
    "        print(\"ERROR: No valid data remaining after cleaning\")\n",
    "        return None\n",
    "\n",
    "    # Simple imputation for features\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    X_imputed = imputer.fit_transform(X)\n",
    "    X = pd.DataFrame(X_imputed, columns=available_features)\n",
    "\n",
    "    print(f\"Final dataset shape: {X.shape}\")\n",
    "\n",
    "    # 4. Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "\n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    check_memory()  # Check memory after preprocessing\n",
    "\n",
    "    # 5. Use lightweight models to prevent crashes\n",
    "    print(\"\\n2. TRAINING LIGHTWEIGHT MODELS...\")\n",
    "\n",
    "    models = {\n",
    "        'Random Forest': RandomForestRegressor(\n",
    "            n_estimators=50,\n",
    "            max_depth=10,\n",
    "            random_state=random_state,\n",
    "            n_jobs=1  # Limit parallel processing\n",
    "        ),\n",
    "        'Linear Regression': LinearRegression()\n",
    "    }\n",
    "\n",
    "    # Try to include XGBoost if available, but with limited resources\n",
    "    try:\n",
    "        from xgboost import XGBRegressor\n",
    "        models['XGBoost'] = XGBRegressor(\n",
    "            n_estimators=50,\n",
    "            max_depth=6,\n",
    "            random_state=random_state,\n",
    "            n_jobs=1,\n",
    "            verbosity=0\n",
    "        )\n",
    "    except ImportError:\n",
    "        print(\"XGBoost not available, using Random Forest and Linear Regression only\")\n",
    "\n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "        print(f\"Training {name}...\")\n",
    "        try:\n",
    "            model.fit(X_train_scaled, y_train)\n",
    "            y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "            # Calculate metrics\n",
    "            mae = mean_absolute_error(y_test, y_pred)\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            rmse = np.sqrt(mse)\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "            results[name] = {\n",
    "                'model': model,\n",
    "                'mae': mae,\n",
    "                'mse': mse,\n",
    "                'rmse': rmse,\n",
    "                'r2': r2,\n",
    "                'predictions': y_pred\n",
    "            }\n",
    "\n",
    "            print(f\"  {name} - R²: {r2:.4f}, MAE: {mae:.2f}, RMSE: {rmse:.2f}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  {name} failed: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "        check_memory()  # Check memory after each model\n",
    "\n",
    "    if not results:\n",
    "        print(\"ERROR: No models trained successfully\")\n",
    "        return None\n",
    "\n",
    "    # 6. Model comparison\n",
    "    print(\"\\n3. MODEL COMPARISON\")\n",
    "\n",
    "    comparison_data = []\n",
    "    for name, result in results.items():\n",
    "        comparison_data.append({\n",
    "            'Model': name,\n",
    "            'R² Score': result['r2'],\n",
    "            'MAE': result['mae'],\n",
    "            'RMSE': result['rmse']\n",
    "        })\n",
    "\n",
    "    comparison_df = pd.DataFrame(comparison_data).sort_values('R² Score', ascending=False)\n",
    "    print(\"Model Performance Comparison:\")\n",
    "    print(comparison_df.to_string(index=False))\n",
    "\n",
    "    # 7. Simple visualization\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    # Model comparison\n",
    "    model_names = comparison_df['Model']\n",
    "    r2_scores = comparison_df['R² Score']\n",
    "\n",
    "    axes[0].bar(model_names, r2_scores, color=['blue', 'green', 'orange'][:len(model_names)])\n",
    "    axes[0].set_title('Model Comparison (R² Score)')\n",
    "    axes[0].set_ylabel('R² Score')\n",
    "    axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "    # Best model predictions\n",
    "    best_model_name = comparison_df.iloc[0]['Model']\n",
    "    best_predictions = results[best_model_name]['predictions']\n",
    "\n",
    "    axes[1].scatter(y_test, best_predictions, alpha=0.6)\n",
    "    axes[1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "    axes[1].set_xlabel('Actual Values')\n",
    "    axes[1].set_ylabel('Predicted Values')\n",
    "    axes[1].set_title(f'{best_model_name} - Actual vs Predicted')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 8. Feature importance for best model\n",
    "    if hasattr(results[best_model_name]['model'], 'feature_importances_'):\n",
    "        importance = results[best_model_name]['model'].feature_importances_\n",
    "        feature_importance = pd.DataFrame({\n",
    "            'feature': available_features,\n",
    "            'importance': importance\n",
    "        }).sort_values('importance', ascending=True)\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.barh(feature_importance['feature'], feature_importance['importance'])\n",
    "        plt.title(f'{best_model_name} - Feature Importance')\n",
    "        plt.xlabel('Importance')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    print(f\"\\nBest model: {best_model_name} (R²: {results[best_model_name]['r2']:.4f})\")\n",
    "\n",
    "    final_memory = check_memory()\n",
    "    print(f\"Final memory usage: {final_memory:.1f}%\")\n",
    "\n",
    "    return {\n",
    "        'results': results,\n",
    "        'best_model': best_model_name,\n",
    "        'best_score': results[best_model_name]['r2'],\n",
    "        'scaler': scaler,\n",
    "        'imputer': imputer,\n",
    "        'features': available_features,\n",
    "        'comparison_df': comparison_df\n",
    "    }\n",
    "\n",
    "# Run the memory-efficient ML pipeline\n",
    "print(\"Starting memory-efficient ML pipeline...\")\n",
    "ml_results = memory_efficient_ml_pipeline(df, target_variable='calories_kcal')\n",
    "\n",
    "if ml_results:\n",
    "    print(\"\\nML Pipeline completed successfully!\")\n",
    "else:\n",
    "    print(\"\\nML Pipeline failed. Check your data and try again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yv7DJEnN9hfE"
   },
   "source": [
    "## 5 - ML advanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hH7OBLoMVEnS"
   },
   "source": [
    "### 5.1 recommendations systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IZVrrjDsVuYM"
   },
   "source": [
    "This comprehensive recommendation system provides:\n",
    "\n",
    "  - Diet-Specific Recommendations: Vegan, vegetarian, keto, paleo, gluten-free\n",
    "\n",
    "  - Ingredient-Based Filtering: Preferred and excluded ingredients\n",
    "\n",
    "  - Cooking Method Preferences: Preferred and excluded cooking methods\n",
    "\n",
    "  - Health Goal Optimization: Weight loss, muscle gain, maintenance, etc.\n",
    "\n",
    "  - Similarity-Based Recommendations: Recipes similar to liked dishes\n",
    "\n",
    "  - User Profiles: Personalized recommendations based on comprehensive profiles\n",
    "\n",
    "  - Advanced Filtering: Calorie ranges, prep time, nutritional density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LKpomz9TVB_R",
    "outputId": "e7f01406-01ae-4e9e-b8ce-9e5b812a0510"
   },
   "outputs": [],
   "source": [
    "class EfficientNutritionalRecommender:\n",
    "    \"\"\"\n",
    "    Memory-efficient recommendation system that won't crash Colab\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, df, max_samples=25000, max_ingredients=200):\n",
    "        \"\"\"\n",
    "        Initialize with memory constraints\n",
    "\n",
    "        Args:\n",
    "            df: DataFrame with recipe data\n",
    "            max_samples: Maximum number of recipes to use (prevents memory issues)\n",
    "            max_ingredients: Maximum ingredients to consider for similarity\n",
    "        \"\"\"\n",
    "        print(f\"Initializing Efficient Recommendation System...\")\n",
    "\n",
    "        # Sample data to prevent memory issues\n",
    "        if len(df) > max_samples:\n",
    "            print(f\"Sampling {max_samples} recipes from {len(df)} total recipes\")\n",
    "            self.df = df.sample(n=max_samples, random_state=42).reset_index(drop=True)\n",
    "        else:\n",
    "            self.df = df.copy().reset_index(drop=True)\n",
    "\n",
    "        self.max_ingredients = max_ingredients\n",
    "        self._prepare_efficient_features()\n",
    "        print(f\"Recommender initialized with {len(self.df)} recipes\")\n",
    "\n",
    "    def _prepare_efficient_features(self):\n",
    "        \"\"\"Prepare lightweight features instead of full one-hot encoding\"\"\"\n",
    "        # Get top ingredients only (limits feature space dramatically)\n",
    "        all_ingredients = []\n",
    "        for ingredients in self.df['ingredients_cleaned']:\n",
    "            if isinstance(ingredients, list):\n",
    "                all_ingredients.extend([ing.lower().strip() for ing in ingredients])\n",
    "\n",
    "        from collections import Counter\n",
    "        ingredient_counter = Counter(all_ingredients)\n",
    "        self.top_ingredients = [ing for ing, count in ingredient_counter.most_common(self.max_ingredients)]\n",
    "\n",
    "        print(f\"Using top {len(self.top_ingredients)} ingredients for recommendations\")\n",
    "\n",
    "        # Create simple dietary flags\n",
    "        self._create_dietary_flags()\n",
    "\n",
    "        # Pre-calculate nutritional scores\n",
    "        self._calculate_nutritional_scores()\n",
    "\n",
    "    def _create_dietary_flags(self):\n",
    "        \"\"\"Create dietary restriction flags efficiently\"\"\"\n",
    "        dietary_restrictions = {\n",
    "            'vegan_restricted': ['meat', 'beef', 'pork', 'chicken', 'fish', 'seafood', 'egg', 'dairy', 'milk', 'cheese', 'butter', 'honey'],\n",
    "            'vegetarian_restricted': ['meat', 'beef', 'pork', 'chicken', 'fish', 'seafood'],\n",
    "            'keto_friendly': ['low carb', 'sugar free', 'keto'],\n",
    "            'gluten_restricted': ['wheat', 'flour', 'bread', 'pasta', 'gluten']\n",
    "        }\n",
    "\n",
    "        def check_dietary_compliance(ingredients, restricted_items):\n",
    "            if not isinstance(ingredients, list):\n",
    "                return False\n",
    "            ingredient_text = ' '.join([str(ing).lower() for ing in ingredients])\n",
    "            return not any(item in ingredient_text for item in restricted_items)\n",
    "\n",
    "        # Create flags\n",
    "        self.df['is_vegan'] = self.df['ingredients_cleaned'].apply(\n",
    "            lambda x: check_dietary_compliance(x, dietary_restrictions['vegan_restricted'])\n",
    "        )\n",
    "        self.df['is_vegetarian'] = self.df['ingredients_cleaned'].apply(\n",
    "            lambda x: check_dietary_compliance(x, dietary_restrictions['vegetarian_restricted'])\n",
    "        )\n",
    "        self.df['is_gluten_free'] = self.df['ingredients_cleaned'].apply(\n",
    "            lambda x: check_dietary_compliance(x, dietary_restrictions['gluten_restricted'])\n",
    "        )\n",
    "\n",
    "        # High protein flag\n",
    "        self.df['is_high_protein'] = self.df['protein_g'] > self.df['protein_g'].quantile(0.7)\n",
    "\n",
    "        # Low calorie flag\n",
    "        self.df['is_low_calorie'] = self.df['calories_kcal'] < self.df['calories_kcal'].quantile(0.3)\n",
    "\n",
    "    def _calculate_nutritional_scores(self):\n",
    "        \"\"\"Pre-calculate scoring metrics\"\"\"\n",
    "        # Nutritional density score\n",
    "        if 'nutritional_density' not in self.df.columns:\n",
    "            self.df['nutritional_density'] = (\n",
    "                self.df['protein_g'] / self.df['calories_kcal'] * 100\n",
    "            ).fillna(0)\n",
    "\n",
    "        # Health score based on multiple factors\n",
    "        self.df['health_score'] = (\n",
    "            (self.df['protein_g'] / self.df['calories_kcal'] * 10).fillna(0) +\n",
    "            self.df['is_high_protein'].astype(int) * 2 +\n",
    "            self.df['is_low_calorie'].astype(int) * 1\n",
    "        )\n",
    "\n",
    "    def recommend_by_diet(self, diet_type, n_recommendations=5, **filters):\n",
    "        \"\"\"\n",
    "        Efficient diet-based recommendations\n",
    "        \"\"\"\n",
    "        diet_filters = {\n",
    "            'vegan': 'is_vegan',\n",
    "            'vegetarian': 'is_vegetarian',\n",
    "            'gluten_free': 'is_gluten_free',\n",
    "            'high_protein': 'is_high_protein',\n",
    "            'low_calorie': 'is_low_calorie'\n",
    "        }\n",
    "\n",
    "        if diet_type not in diet_filters:\n",
    "            available_diets = list(diet_filters.keys())\n",
    "            print(f\"Diet type '{diet_type}' not supported. Available: {available_diets}\")\n",
    "            return None\n",
    "\n",
    "        # Filter by diet\n",
    "        diet_column = diet_filters[diet_type]\n",
    "        filtered_df = self.df[self.df[diet_column] == True].copy()\n",
    "\n",
    "        if len(filtered_df) == 0:\n",
    "            print(f\"No {diet_type} recipes found\")\n",
    "            return self._get_fallback_recommendations(n_recommendations)\n",
    "\n",
    "        # Apply additional filters\n",
    "        filtered_df = self._apply_filters(filtered_df, **filters)\n",
    "\n",
    "        if len(filtered_df) == 0:\n",
    "            print(f\"No {diet_type} recipes match your criteria\")\n",
    "            return self._get_fallback_recommendations(n_recommendations)\n",
    "\n",
    "        # Sort by health score and nutritional density\n",
    "        recommendations = filtered_df.nlargest(n_recommendations, ['health_score', 'nutritional_density'])\n",
    "\n",
    "        return self._format_recommendations(recommendations, f\"{diet_type.title()} Recommendations\")\n",
    "\n",
    "    def recommend_by_ingredients(self, preferred_ingredients, excluded_ingredients=None, n_recommendations=5, **filters):\n",
    "        \"\"\"\n",
    "        Efficient ingredient-based recommendations\n",
    "        \"\"\"\n",
    "        if excluded_ingredients is None:\n",
    "            excluded_ingredients = []\n",
    "\n",
    "        preferred_ingredients = [ing.lower().strip() for ing in preferred_ingredients]\n",
    "        excluded_ingredients = [ing.lower().strip() for ing in excluded_ingredients]\n",
    "\n",
    "        # Score recipes by ingredient matches\n",
    "        def calculate_ingredient_score(ingredients):\n",
    "            if not isinstance(ingredients, list):\n",
    "                return 0\n",
    "\n",
    "            ingredient_text = ' '.join([str(ing).lower() for ing in ingredients])\n",
    "\n",
    "            # Calculate preference score\n",
    "            preference_score = sum(2 for pref in preferred_ingredients if pref in ingredient_text)\n",
    "\n",
    "            # Penalize for excluded ingredients\n",
    "            exclusion_penalty = sum(5 for excl in excluded_ingredients if excl in ingredient_text)\n",
    "\n",
    "            return max(0, preference_score - exclusion_penalty)\n",
    "\n",
    "        self.df['ingredient_score'] = self.df['ingredients_cleaned'].apply(calculate_ingredient_score)\n",
    "\n",
    "        # Get recipes with positive scores\n",
    "        filtered_df = self.df[self.df['ingredient_score'] > 0].copy()\n",
    "\n",
    "        if len(filtered_df) == 0:\n",
    "            print(\"No recipes found matching your ingredient preferences\")\n",
    "            return self._get_fallback_recommendations(n_recommendations)\n",
    "\n",
    "        # Apply additional filters\n",
    "        filtered_df = self._apply_filters(filtered_df, **filters)\n",
    "\n",
    "        if len(filtered_df) == 0:\n",
    "            print(\"No recipes match your ingredient preferences and filters\")\n",
    "            return self._get_fallback_recommendations(n_recommendations)\n",
    "\n",
    "        # Sort by ingredient score and health score\n",
    "        recommendations = filtered_df.nlargest(n_recommendations, ['ingredient_score', 'health_score'])\n",
    "\n",
    "        return self._format_recommendations(recommendations, \"Ingredient-Based Recommendations\")\n",
    "\n",
    "    def recommend_by_nutrition_goals(self, goal, target_calories=None, n_recommendations=5, **filters):\n",
    "        \"\"\"\n",
    "        Nutrition goal-based recommendations\n",
    "        \"\"\"\n",
    "        goal_configs = {\n",
    "            'weight_loss': {\n",
    "                'max_calories': 400,\n",
    "                'min_protein': 15,\n",
    "                'sort_by': ['is_low_calorie', 'health_score'],\n",
    "                'ascending': [False, False]\n",
    "            },\n",
    "            'muscle_gain': {\n",
    "                'min_protein': 20,\n",
    "                'min_calories': 300,\n",
    "                'sort_by': ['is_high_protein', 'protein_g'],\n",
    "                'ascending': [False, False]\n",
    "            },\n",
    "            'healthy_eating': {\n",
    "                'min_protein': 10,\n",
    "                'sort_by': ['health_score', 'nutritional_density'],\n",
    "                'ascending': [False, False]\n",
    "            }\n",
    "        }\n",
    "\n",
    "        if goal not in goal_configs:\n",
    "            available_goals = list(goal_configs.keys())\n",
    "            print(f\"Goal '{goal}' not supported. Available: {available_goals}\")\n",
    "            return None\n",
    "\n",
    "        config = goal_configs[goal]\n",
    "        filtered_df = self.df.copy()\n",
    "\n",
    "        # Apply goal-specific filters\n",
    "        if 'max_calories' in config:\n",
    "            filtered_df = filtered_df[filtered_df['calories_kcal'] <= config['max_calories']]\n",
    "\n",
    "        if 'min_calories' in config:\n",
    "            filtered_df = filtered_df[filtered_df['calories_kcal'] >= config['min_calories']]\n",
    "\n",
    "        if 'min_protein' in config:\n",
    "            filtered_df = filtered_df[filtered_df['protein_g'] >= config['min_protein']]\n",
    "\n",
    "        # Apply target calories if specified\n",
    "        if target_calories:\n",
    "            calorie_range = target_calories * 0.2  # 20% tolerance\n",
    "            filtered_df = filtered_df[\n",
    "                (filtered_df['calories_kcal'] >= target_calories - calorie_range) &\n",
    "                (filtered_df['calories_kcal'] <= target_calories + calorie_range)\n",
    "            ]\n",
    "\n",
    "        # Apply additional filters\n",
    "        filtered_df = self._apply_filters(filtered_df, **filters)\n",
    "\n",
    "        if len(filtered_df) == 0:\n",
    "            print(f\"No recipes found for {goal} goal\")\n",
    "            return self._get_fallback_recommendations(n_recommendations)\n",
    "\n",
    "        # Sort according to goal configuration\n",
    "        recommendations = filtered_df.sort_values(\n",
    "            config['sort_by'],\n",
    "            ascending=config['ascending']\n",
    "        ).head(n_recommendations)\n",
    "\n",
    "        return self._format_recommendations(recommendations, f\"{goal.replace('_', ' ').title()} Recommendations\")\n",
    "\n",
    "    def recommend_similar_recipes(self, recipe_index, n_recommendations=5, **filters):\n",
    "        \"\"\"\n",
    "        Find similar recipes using simplified similarity calculation\n",
    "        \"\"\"\n",
    "        if recipe_index >= len(self.df) or recipe_index < 0:\n",
    "            print(\"Invalid recipe index\")\n",
    "            return None\n",
    "\n",
    "        target_recipe = self.df.iloc[recipe_index]\n",
    "\n",
    "        # Calculate simple similarity based on nutritional profile\n",
    "        def calculate_similarity(row):\n",
    "            # Nutritional similarity (normalized)\n",
    "            nutrition_diff = abs(\n",
    "                (row['calories_kcal'] - target_recipe['calories_kcal']) / max(target_recipe['calories_kcal'], 1) +\n",
    "                (row['protein_g'] - target_recipe['protein_g']) / max(target_recipe['protein_g'], 1) +\n",
    "                (row['fat_g'] - target_recipe['fat_g']) / max(target_recipe['fat_g'], 1)\n",
    "            )\n",
    "\n",
    "            # Ingredient overlap (simplified)\n",
    "            if isinstance(row['ingredients_cleaned'], list) and isinstance(target_recipe['ingredients_cleaned'], list):\n",
    "                target_ingredients = set([ing.lower() for ing in target_recipe['ingredients_cleaned']])\n",
    "                recipe_ingredients = set([ing.lower() for ing in row['ingredients_cleaned']])\n",
    "\n",
    "                if len(target_ingredients) > 0:\n",
    "                    ingredient_overlap = len(target_ingredients.intersection(recipe_ingredients)) / len(target_ingredients)\n",
    "                else:\n",
    "                    ingredient_overlap = 0\n",
    "            else:\n",
    "                ingredient_overlap = 0\n",
    "\n",
    "            # Combined similarity (lower is more similar)\n",
    "            return nutrition_diff - (ingredient_overlap * 0.5)\n",
    "\n",
    "        # Calculate similarities\n",
    "        similarities = self.df.apply(calculate_similarity, axis=1)\n",
    "\n",
    "        # Get most similar recipes (excluding the target recipe itself)\n",
    "        similar_indices = similarities.nsmallest(n_recommendations + 1).index[1:]  # Skip first (self)\n",
    "        similar_recipes = self.df.loc[similar_indices].copy()\n",
    "\n",
    "        # Apply additional filters\n",
    "        similar_recipes = self._apply_filters(similar_recipes, **filters)\n",
    "\n",
    "        if len(similar_recipes) == 0:\n",
    "            print(\"No similar recipes found matching your criteria\")\n",
    "            return self._get_fallback_recommendations(n_recommendations)\n",
    "\n",
    "        return self._format_recommendations(similar_recipes.head(n_recommendations), \"Similar Recipes\")\n",
    "\n",
    "    def _apply_filters(self, df, **filters):\n",
    "        \"\"\"Apply additional filters efficiently\"\"\"\n",
    "        filtered_df = df.copy()\n",
    "\n",
    "        # Calorie filters\n",
    "        if 'min_calories' in filters:\n",
    "            filtered_df = filtered_df[filtered_df['calories_kcal'] >= filters['min_calories']]\n",
    "        if 'max_calories' in filters:\n",
    "            filtered_df = filtered_df[filtered_df['calories_kcal'] <= filters['max_calories']]\n",
    "\n",
    "        # Protein filters\n",
    "        if 'min_protein' in filters:\n",
    "            filtered_df = filtered_df[filtered_df['protein_g'] >= filters['min_protein']]\n",
    "        if 'max_protein' in filters:\n",
    "            filtered_df = filtered_df[filtered_df['protein_g'] <= filters['max_protein']]\n",
    "\n",
    "        # Food type filter\n",
    "        if 'food_type' in filters and 'food_type_standardized' in filtered_df.columns:\n",
    "            filtered_df = filtered_df[filtered_df['food_type_standardized'] == filters['food_type']]\n",
    "\n",
    "        return filtered_df\n",
    "\n",
    "    def _get_fallback_recommendations(self, n_recommendations):\n",
    "        \"\"\"Provide fallback recommendations\"\"\"\n",
    "        print(\"Showing general healthy recommendations as fallback\")\n",
    "        fallback = self.df.nlargest(n_recommendations, 'health_score')\n",
    "        return self._format_recommendations(fallback, \"General Recommendations (Fallback)\")\n",
    "\n",
    "    def _format_recommendations(self, recommendations, title):\n",
    "        \"\"\"Format recommendations for display\"\"\"\n",
    "        results = []\n",
    "\n",
    "        for idx, (_, recipe) in enumerate(recommendations.iterrows()):\n",
    "            result = {\n",
    "                'rank': idx + 1,\n",
    "                'recipe_id': recipe.name,\n",
    "                'name': recipe.get('dish_name', 'Unknown Dish'),\n",
    "                'calories': round(recipe.get('calories_kcal', 0), 1),\n",
    "                'protein': round(recipe.get('protein_g', 0), 1),\n",
    "                'carbs': round(recipe.get('carbohydrate_g', 0), 1),\n",
    "                'fat': round(recipe.get('fat_g', 0), 1),\n",
    "                'health_score': round(recipe.get('health_score', 0), 2),\n",
    "                'ingredients': recipe.get('ingredients_cleaned', [])[:5],  # First 5 ingredients\n",
    "                'cooking_methods': recipe.get('cooking_methods_cleaned', []),\n",
    "                'is_vegan': recipe.get('is_vegan', False),\n",
    "                'is_vegetarian': recipe.get('is_vegetarian', False),\n",
    "                'is_high_protein': recipe.get('is_high_protein', False)\n",
    "            }\n",
    "            results.append(result)\n",
    "\n",
    "        return {\n",
    "            'title': title,\n",
    "            'count': len(results),\n",
    "            'recommendations': results\n",
    "        }\n",
    "\n",
    "    def print_recommendations(self, recommendations):\n",
    "        \"\"\"Print recommendations in a readable format\"\"\"\n",
    "        if not recommendations:\n",
    "            print(\"No recommendations to display\")\n",
    "            return\n",
    "\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"{recommendations['title']}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"Found {recommendations['count']} recommendations\\n\")\n",
    "\n",
    "        for rec in recommendations['recommendations']:\n",
    "            print(f\"{rec['rank']}. {rec['name']}\")\n",
    "            print(f\"   Calories: {rec['calories']} kcal | Protein: {rec['protein']}g\")\n",
    "            print(f\"   Carbs: {rec['carbs']}g | Fat: {rec['fat']}g\")\n",
    "            print(f\"   Health Score: {rec['health_score']}\")\n",
    "\n",
    "            # Dietary flags\n",
    "            flags = []\n",
    "            if rec['is_vegan']: flags.append('Vegan')\n",
    "            if rec['is_vegetarian']: flags.append('Vegetarian')\n",
    "            if rec['is_high_protein']: flags.append('High Protein')\n",
    "            if flags:\n",
    "                print(f\"   Tags: {', '.join(flags)}\")\n",
    "\n",
    "            print(f\"   Ingredients: {', '.join(rec['ingredients'])}\")\n",
    "            if rec['cooking_methods']:\n",
    "                print(f\"   Cooking: {', '.join(rec['cooking_methods'])}\")\n",
    "            print()\n",
    "\n",
    "# Demonstration function\n",
    "def demonstrate_efficient_recommender(df):\n",
    "    \"\"\"Demonstrate the efficient recommender system\"\"\"\n",
    "    print(\"Initializing Efficient Recommendation System...\")\n",
    "\n",
    "    try:\n",
    "        # Initialize with reasonable sample size\n",
    "        recommender = EfficientNutritionalRecommender(df, max_samples=25000, max_ingredients=200)\n",
    "\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"EFFICIENT RECOMMENDATION SYSTEM DEMO\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "        # 1. Diet-based recommendations\n",
    "        print(\"\\n1. VEGAN RECOMMENDATIONS\")\n",
    "        vegan_recs = recommender.recommend_by_diet('vegan', n_recommendations=3)\n",
    "        if vegan_recs:\n",
    "            recommender.print_recommendations(vegan_recs)\n",
    "\n",
    "        # 2. Ingredient-based recommendations\n",
    "        print(\"\\n2. CHICKEN-BASED RECIPES (excluding dairy)\")\n",
    "        ingredient_recs = recommender.recommend_by_ingredients(\n",
    "            preferred_ingredients=['chicken', 'vegetable'],\n",
    "            excluded_ingredients=['cheese', 'cream'],\n",
    "            n_recommendations=3\n",
    "        )\n",
    "        if ingredient_recs:\n",
    "            recommender.print_recommendations(ingredient_recs)\n",
    "\n",
    "        # 3. Nutrition goal recommendations\n",
    "        print(\"\\n3. WEIGHT LOSS RECOMMENDATIONS\")\n",
    "        weight_loss_recs = recommender.recommend_by_nutrition_goals('weight_loss', n_recommendations=3)\n",
    "        if weight_loss_recs:\n",
    "            recommender.print_recommendations(weight_loss_recs)\n",
    "\n",
    "        # 4. Similar recipes\n",
    "        if len(recommender.df) > 0:\n",
    "            print(\"\\n4. RECIPES SIMILAR TO FIRST RECIPE\")\n",
    "            similar_recs = recommender.recommend_similar_recipes(0, n_recommendations=3)\n",
    "            if similar_recs:\n",
    "                recommender.print_recommendations(similar_recs)\n",
    "\n",
    "        return recommender\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in recommendation system: {str(e)}\")\n",
    "        print(\"This may be due to missing columns or data formatting issues\")\n",
    "        return None\n",
    "\n",
    "recommender = demonstrate_efficient_recommender(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QDSTr5wZpxux"
   },
   "outputs": [],
   "source": [
    "\n",
    "# recommender example:\n",
    "if recommender:\n",
    "    # Get vegan recommendations\n",
    "    vegan_recs = recommender.recommend_by_diet('vegan', n_recommendations=5)\n",
    "\n",
    "    # Get ingredient-based recommendations\n",
    "    chicken_recs = recommender.recommend_by_ingredients(['chicken', 'broccoli'])\n",
    "\n",
    "    # Get nutrition goal recommendations\n",
    "    weight_loss_recs = recommender.recommend_by_nutrition_goals('weight_loss')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "lmDfUUbCq8LX"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "05b6224556d345ef932a8ad35f38cb31": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "177d3a0d672e49f0ab1a544d1543b880": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1fa710b3408a45c4856a0294133aef69",
      "placeholder": "​",
      "style": "IPY_MODEL_af77dc19727f49c98b0170c24364ba62",
      "value": "README.md: "
     }
    },
    "1fa710b3408a45c4856a0294133aef69": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "208741a879034a9d8de0c055b14a0da9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_05b6224556d345ef932a8ad35f38cb31",
      "max": 28598273,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_76f6ae8421f34f96a8a941bf286e000c",
      "value": 28598273
     }
    },
    "2e684179c7064d1da129fa0f08f12d53": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3d7f9f9ab903465e91e6762234f78d20": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "45f16f53e40640f8a72d51e2a63f612c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_97580ecf30b54bf2bb7ce4ff19dc4079",
      "max": 100000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b2208f7b3ea34aff8f81e29bc1e2d29c",
      "value": 100000
     }
    },
    "461c91b1930b4abb97d3c61186c7c4ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_633a675a69a0427fa105578b9b02dbc0",
      "placeholder": "​",
      "style": "IPY_MODEL_c279e35c221740ffb2e2c1bc5144e59c",
      "value": " 28.6M/28.6M [00:01&lt;00:00, 20.0MB/s]"
     }
    },
    "51c54e5110504189bce149351438124b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "529ae4a0950f4a04b5faf604c47704b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d039a0976a544421bcf7166d193611a4",
       "IPY_MODEL_208741a879034a9d8de0c055b14a0da9",
       "IPY_MODEL_461c91b1930b4abb97d3c61186c7c4ae"
      ],
      "layout": "IPY_MODEL_8717dfc324024341963f9988c7c9d9fe"
     }
    },
    "5917b42ce4cf4907b10c2ecc4479aa07": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5b733c932d654d058ca6a17028c9a622": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6211e4a268c044409dbf5a511921b849": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_51c54e5110504189bce149351438124b",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5917b42ce4cf4907b10c2ecc4479aa07",
      "value": 1
     }
    },
    "633a675a69a0427fa105578b9b02dbc0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "681f6b8bdb6c408d9140117ceab7f2c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2e684179c7064d1da129fa0f08f12d53",
      "placeholder": "​",
      "style": "IPY_MODEL_5b733c932d654d058ca6a17028c9a622",
      "value": "Generating train split: 100%"
     }
    },
    "729dded1f5414924ae378b53875cf9fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_177d3a0d672e49f0ab1a544d1543b880",
       "IPY_MODEL_6211e4a268c044409dbf5a511921b849",
       "IPY_MODEL_94deabc2b8bc42f2b482a983aed0b6db"
      ],
      "layout": "IPY_MODEL_3d7f9f9ab903465e91e6762234f78d20"
     }
    },
    "76f6ae8421f34f96a8a941bf286e000c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7eeab89049ae4d2f9ae9d5305f0da15a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8097e060770e48a6ad4ec32baf3c91cb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8520c656f3784efeaffdbdb9dde5d5cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8717dfc324024341963f9988c7c9d9fe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "94deabc2b8bc42f2b482a983aed0b6db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fa7bbb53d48247c7b796891812024835",
      "placeholder": "​",
      "style": "IPY_MODEL_a424a83096964f79b30e223c34b1cf91",
      "value": " 14.6k/? [00:00&lt;00:00, 223kB/s]"
     }
    },
    "97580ecf30b54bf2bb7ce4ff19dc4079": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a424a83096964f79b30e223c34b1cf91": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "af77dc19727f49c98b0170c24364ba62": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b2208f7b3ea34aff8f81e29bc1e2d29c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c279e35c221740ffb2e2c1bc5144e59c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d039a0976a544421bcf7166d193611a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7eeab89049ae4d2f9ae9d5305f0da15a",
      "placeholder": "​",
      "style": "IPY_MODEL_e7e3a4412ed2426db9314d84bcedffe9",
      "value": "MM-Food-100K.csv: 100%"
     }
    },
    "dc5dd3f3df8c4ce29ef041e45f69bf52": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_efb19e537b3b49f6b8b778a18393ce97",
      "placeholder": "​",
      "style": "IPY_MODEL_8520c656f3784efeaffdbdb9dde5d5cf",
      "value": " 100000/100000 [00:01&lt;00:00, 64485.58 examples/s]"
     }
    },
    "e7e3a4412ed2426db9314d84bcedffe9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "efb19e537b3b49f6b8b778a18393ce97": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f903f92a57764bf0a38f0dd92af03f56": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_681f6b8bdb6c408d9140117ceab7f2c3",
       "IPY_MODEL_45f16f53e40640f8a72d51e2a63f612c",
       "IPY_MODEL_dc5dd3f3df8c4ce29ef041e45f69bf52"
      ],
      "layout": "IPY_MODEL_8097e060770e48a6ad4ec32baf3c91cb"
     }
    },
    "fa7bbb53d48247c7b796891812024835": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
